{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigrant cities data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "In the Udacity provided project, I'll work with three datasets to complete the project. The main dataset will include data on immigration to the United States, and supplementary datasets will include data on airport codes, U.S. city demographics, and temperature data.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re\n",
    "pd.set_option('display.max_columns', 30) # to view all columns \n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count,when,isnan, col, udf, year, month, round, dayofweek, weekofyear, isnull\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The objective of this project is to collect data from three different sources and produce fact and dimension tables in order to conduct immigration analysis using Spark and Pandas in the United States utilizing criteria such as city average temperature, city demographics, population number, and percentage.\n",
    "\n",
    "The end-user can use this data to get insights into the population size of US cities and their ethnicity for other studies such as clothing sales of what they prefer and not, food favorites, etc.\n",
    "\n",
    "In this project, the dataset can answer questions like the average temperature of US cities at different times. Number and percentage of US cities people. Visa and the transportation type of immigrants, etc.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "**I94 Immigration Data:** This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://www.trade.gov/national-travel-and-tourism-office) is where the data comes from. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "\n",
    "**World Temperature Data:** This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "\n",
    "**U.S. City Demographic Data:** This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_i94 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_temp = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_demo = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load('us-cities-demographics.csv')\n",
    "df_airport = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load('airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check number and duplicates of rows for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Number immigration rows: ',df_i94.count())\n",
    "print('Number of distinct immigration rows: ',df_i94.distinct().count())\n",
    "print('Number demographics rows: ',df_demo.count())\n",
    "print('Number of distinct demographics rows: ',df_demo.distinct().count())\n",
    "print('Number temperature rows: ',df_temp.count())\n",
    "print('Number of distinct temperature rows: ',df_temp.distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check Schema for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Immigration Schema:')\n",
    "df_i94.printSchema()\n",
    "print('Demographics Schema:')\n",
    "df_demo.printSchema()\n",
    "print('Temperature Schema:')\n",
    "df_temp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Display five records for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check the number of nulls for each column in each dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_i94.columns]\n",
    "   ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "occup, entdepu and insnum columns seem to be useless since they are over 3 million records are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_demo.columns]\n",
    "   ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are few null values, the dataset will not be affected dropping these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_temp.columns]\n",
    "   ).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are a lot of null values, these nulls will be dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There are a lot of null values in iata_code column, these nulls will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check duplicates in cicid column\n",
    "if df_i94.count() > df_i94.dropDuplicates(['cicid']).count():\n",
    "    raise ValueError('Data has duplicates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns from Immigration dataset\n",
    "cols = ('occup', 'entdepu','insnum')\n",
    "df_i94 = df_i94.drop(*cols)\n",
    "df_i94 = df_i94.dropna(how=\"any\", subset=['i94port', 'i94addr', 'gender'])\n",
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Number of demographics rows before dropping null values: ',df_demo.count())\n",
    "df_demo = df_demo.na.drop(\"any\")\n",
    "print('Number of demographics rows after dropping null values: ', df_demo.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_demo.columns]\n",
    "   ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Number of temperature rows before dropping null values: ',df_temp.count())\n",
    "df_temp = df_temp.na.drop(\"any\")\n",
    "print('Number of temperature rows after dropping null values: ', df_temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temp.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_temp.columns]\n",
    "   ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create list of valid ports\n",
    "i94_sas_label_descriptions = 'I94_SAS_Labels_Descriptions.SAS'\n",
    "with open(i94_sas_label_descriptions) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "\n",
    "# Create list of valid states\n",
    "valid_states = df_demo.toPandas()['State Code'].unique()\n",
    "print(valid_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create udf to convert SAS date to PySpark date \n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None\n",
    "\n",
    "# Create udf to validate state\n",
    "@udf(StringType())\n",
    "def validate_state(x):  \n",
    "    if x in valid_states:\n",
    "        return x\n",
    "    return 'null'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract valid states \n",
    "df_i94_cleaned = df_i94.withColumn('i94addr', validate_state(df_i94['i94addr']))\n",
    "\n",
    "# Convert arrdate from SAS to PySpark format\n",
    "df_i94_cleaned = df_i94.withColumn('arrdate', convert_datetime(df_i94['arrdate']))\n",
    "\n",
    "# filter out null values\n",
    "df_i94_cleaned = df_i94_cleaned.filter(df_i94_cleaned.i94addr != 'null')\n",
    "\n",
    "\n",
    "df_i94_staging = df_i94_cleaned.select(col('cicid').alias('id'), \n",
    "                                       col('arrdate').alias('date'),\n",
    "                                       col('i94port').alias('city_code'),\n",
    "                                       col('i94addr').alias('state_code'),\n",
    "                                       col('i94bir').alias('age'),\n",
    "                                       col('gender').alias('gender'),\n",
    "                                       col('i94visa').alias('visa_type'),\n",
    "                                       col('i94mode').alias('transportation_type'),\n",
    "                                       'count').drop_duplicates()\n",
    "\n",
    "df_i94_staging.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate percentages of numeric columns and create new ones\n",
    "df_demo_cleaned = df_demo.withColumn(\"median_age\", df_demo['Median Age']) \\\n",
    "    .withColumn(\"total_pop\",df_demo['Total Population'])\\\n",
    "    .withColumn(\"num_male_pop\", df_demo['Male Population']) \\\n",
    "    .withColumn(\"prct_male_pop\", (df_demo['Male Population'] / df_demo['Total Population']) * 100) \\\n",
    "    .withColumn(\"num_female_pop\", df_demo['Female Population']) \\\n",
    "    .withColumn(\"prct_female_pop\", (df_demo['Female Population'] / df_demo['Total Population']) * 100) \\\n",
    "    .withColumn(\"num_veterans\", df_demo['Number of Veterans']) \\\n",
    "    .withColumn(\"prct_veterans\", (df_demo['Number of Veterans'] / df_demo['Total Population']) * 100) \\\n",
    "    .withColumn(\"num_foreign_born\", df_demo['Foreign-born'] ) \\\n",
    "    .withColumn(\"prct_foreign_born\", (df_demo['Foreign-born'] / df_demo['Total Population']) * 100) \\\n",
    "    .withColumn(\"race\", df_demo['Race']) \\\n",
    "    .withColumn(\"state_code\",df_demo['State Code'])\\\n",
    "    .withColumn(\"city\",df_demo['City'])\\\n",
    "    .dropna(how='any', subset=[\"state_code\"])\n",
    "\n",
    "df_demo_staging = df_demo_cleaned.select(\"median_age\",'total_pop','num_male_pop','prct_male_pop',\"num_female_pop\",\n",
    "                                         \"prct_female_pop\",\"num_veterans\",\"prct_veterans\",\"num_foreign_born\",\"prct_foreign_born\",\n",
    "                                         \"race\",'state_code','city' )\n",
    "                                         \n",
    "\n",
    "df_demo_staging.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter out the temperature dataset by United States\n",
    "\n",
    "df_temp_cleaned= df_temp.filter(col('Country') == 'United States') \\\n",
    "    .withColumn('year', year(df_temp['dt'])) \\\n",
    "    .withColumn('month', month(df_temp['dt'])) \\\n",
    "    .withColumn('week#',weekofyear(df_temp['dt']))\\\n",
    "    .withColumn(\"city\", df_temp[\"City\"])\\\n",
    "    .withColumn(\"AverageTemperature\", col(\"AverageTemperature\").cast(\"float\")) \\\n",
    "    .dropna(how='any', subset=[\"city\"])\n",
    "\n",
    "# use temperatures from the year 2006 and above\n",
    "df_temp_cleaned = df_temp_cleaned.filter(df_temp_cleaned[\"year\"] >= 2006)\n",
    "\n",
    "df_temp_staging = df_temp_cleaned.select(col('year'), \n",
    "                                         col('month'), \n",
    "                                         col('week#'),\n",
    "                                         col('city'),\n",
    "                                         round(col('AverageTemperature'), 1).alias('avg_temperature'),\n",
    "                                         col('Latitude'), \n",
    "                                         col('Longitude')).drop_duplicates()\n",
    "\n",
    "df_temp_staging.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The data model used for this project is the Star Schema model.\n",
    "\n",
    "This model leading to simpler, faster SQL queries. We use this model over the snowflake schema because we have few tables and to make it easy for business analysts to use SQL. \n",
    "\n",
    "#### Staging tables:\n",
    "| Immigration stage | Demographics stage | Temperature stage |\n",
    "|:-----|:------:|:-----:|\n",
    "|id                   |total_pop              |year\n",
    "|date                 |num_male_pop          | month\n",
    "|city_code            |prct_male_pop         |week#\n",
    "|state_code           |num_female_pop        | city\n",
    "|age                  |prct_female_pop         | avg_temperature\n",
    "|gender               |num_veterans           | Latitude\n",
    "|visa_type           |prct_veterans         |Longitude\n",
    "|transportation_type |num_foreign_born\n",
    "|                     |prct_foreign_born\n",
    "|                      |race  \n",
    "|                     |  state_code \n",
    "|                      |city\n",
    "|                     | median_age\n",
    "\n",
    "\n",
    "\n",
    "#### Fact table:\n",
    " | Immigration fact|\n",
    " | ----|\n",
    " |id|\n",
    " | date|\n",
    " |city|\n",
    " | city_code|\n",
    " |state_code|\n",
    " | count|\n",
    " \n",
    "\n",
    "#### Dimension  tables\n",
    "|immigration dim | demographics dim| temperature dim | time dim\n",
    "|:----|:---:|:---:|:---|\n",
    "|id|                 state_code        |city| date\n",
    "|age|                city              | year| year\n",
    "|visa_type           | median_age     |  month| month\n",
    "|transportation_type| num_male_pop      |week#| week#\n",
    "|   gender           |prct_male_pop     |avg_temperature|day\n",
    "|                    |num_female_pop|\n",
    "|                     |prct_female_pop|\n",
    "|                   | num_veterans| \n",
    "|                     |prct_veterans|\n",
    "|                      |num_foreign_born|\n",
    "|                    |  prct_foreign_born|\n",
    "|                  |total_pop| \n",
    "|                  |race| \n",
    "|                  |   Longitude  |\n",
    "|                   | Latitude|\n",
    "\n",
    "\n",
    "          \n",
    "    \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "Listing the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Clean the data from null values, duplicates, etc\n",
    "2. Load staging tables.\n",
    "3. Create fact and dimension tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Building the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_dim = df_i94_staging.select('id','age','visa_type','transportation_type','gender').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographics_dim =df_demo_staging.join(df_temp_staging,'city').select('state_code',\n",
    "                                                                         'city',\n",
    "                                                                         'median_age',\n",
    "                                                                         'total_pop',\n",
    "                                                                         'num_male_pop',\n",
    "                                                                         'prct_male_pop',\n",
    "                                                                         'num_female_pop',\n",
    "                                                                         'prct_female_pop',\n",
    "                                                                         'num_veterans',\n",
    "                                                                         'prct_veterans',\n",
    "                                                                         'num_foreign_born',\n",
    "                                                                         'prct_foreign_born',\n",
    "                                                                         'race',\n",
    "                                                                         'Longitude',\n",
    "                                                                         'Latitude').drop_duplicates()\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demographics_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temperature_dim = df_temp_staging.select('city','year','month','week#','avg_temperature').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_temperature_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_fact = df_i94_staging.join(df_demographics_dim,'state_code').join(df_temperature_dim,'city').select('id',\n",
    "                                                                                                                  'date',\n",
    "                                                                                                                  'city',\n",
    "                                                                                                                  'city_code',\n",
    "                                                                                                                  'state_code',\n",
    "                                                                                                                  'count').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration_fact.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time_dim = df_i94_staging.select('date')\\\n",
    "                            .withColumn('year', year(df_i94_staging['date']))\\\n",
    "                            .withColumn('month', month(df_i94_staging['date']))\\\n",
    "                            .withColumn('day',dayofweek(df_i94_staging['date']))\\\n",
    "                            .withColumn('week#',weekofyear(df_i94_staging['date'])).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_time_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to check tables availability \n",
    "def check_tables(df):\n",
    "    if df is not None:\n",
    "        print(\"Data quality check PASSED.\\nFact and Dimension tables are available.\")\n",
    "        return True      \n",
    "    else:\n",
    "        print(\"Data quality check failed.\\nThere are some tables that are missing!\")\n",
    "        return False\n",
    "        \n",
    "check_tables(df_immigration_dim) & \\\n",
    "check_tables(df_demographics_dim) & \\\n",
    "check_tables(df_temperature_dim) &\\\n",
    "check_tables(df_immigration_fact) & \\\n",
    "check_tables(df_time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Function to check if there are values that exist in tables\n",
    "def values_check(df):\n",
    "    if df.count() !=0:\n",
    "        print(\"Data quality check passed.\\nValues in Fact and Dimension tables are available.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Data quality check failed.\\nThere are some tables that are empty.\")\n",
    "        return False\n",
    "\n",
    "values_check(df_immigration_dim) & \\\n",
    "values_check(df_demographics_dim) & \\\n",
    "values_check(df_temperature_dim) & \\\n",
    "values_check(df_immigration_fact) & \\\n",
    "values_check(df_time_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### a query to validate the data model\n",
    "filter the data by transportation type and show the id and gender column.\n",
    "note: 2 means Sea, 1 means Air and 3 means Land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a query to validate the data model\n",
    "df_immigration_dim.filter('transportation_type = 2').select(\"id\",\"gender\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    " \n",
    "    \n",
    " | Immigration fact|description|\n",
    " | ----|-\n",
    "  |id:| id \n",
    " | date:| arrival date \n",
    " |city:| arrival city \n",
    "  | city_code:| arrival city code\n",
    "  |state_code:| arrival state code\n",
    " | count:| used to count how many arrival to US\n",
    "\n",
    " &nbsp;\n",
    " \n",
    "|immigration dim | description|\n",
    "|:----|-|\n",
    "|id:|   immigrant's id            \n",
    "|age:|   immigrant's age             \n",
    "|visa_type:   |    immigrant's visa type     \n",
    "|transportation_type:| immigrant's transportation type\n",
    "|   gender:  |  immigrant's gender        \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|demographics dim| description|\n",
    "|:----|-|\n",
    "|state_code:        |city port code|\n",
    "|city:              | city name|\n",
    "| median_age:     | median age of the city|\n",
    "| num_male_pop:  |  number of the male population \n",
    "|prct_male_pop:  |   percentage of the male population\n",
    "|num_female_pop:| number of the female population\n",
    "|prct_female_pop:|percentage of the female population\n",
    "| num_veterans:| number of the veterans population\n",
    "|prct_veterans:| percentage of the veterans population\n",
    "|num_foreign_born:| number of the foreign population\n",
    "|  prct_foreign_born:|percentage of the foreign population\n",
    "|total_pop:| total number of the city's population\n",
    "|race:| Respondent race\n",
    "|Longitude:  | city longitude\n",
    "| Latitude:| city latitude\n",
    "\n",
    "&nbsp;\n",
    "\n",
    " |temperature dim | description|\n",
    "|:----|-|\n",
    "|city:| city name\n",
    "| year:| year of the record\n",
    "|  month:| month of the record \n",
    "|week#:| week of the record \n",
    "|avg_temperature:| average temperature\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "| time dim|description|\n",
    "|:---|--|\n",
    "| date:|date of the record|\n",
    "| year:|year of the record|\n",
    "| month:|month of the record|\n",
    "| week#:|week of the record |\n",
    "|day:|day week of the record |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "Spark is chosen for this project as it isprovides a faster and more general data processing platform. Spark lets you run programs up to 100x faster in memory, or 10x faster on disk, than Hadoop. \n",
    "\n",
    "The data is used for reporting purposes. Whenever new data is needed, this code provides the ability to have cleaned data and organized.\n",
    "\n",
    "How you would approach the problem differently under the following scenarios:\n",
    "\n",
    "If the data was increased by 100x: In the future, we could explore scaling up the number of EC2 instances hosting Spark, as well as adding more Spark work nodes. Processing time should be able to be sped up as a result of increased capacity, which might come from either vertical or horizontal scaling.\n",
    "\n",
    "If the data populates a dashboard that must be updated on a daily basis by 7am every day: We might explore utilizing Airflow to plan and automate the data pipeline jobs, which would be quite convenient. We may be able to satisfy customer requirements thanks to the built-in retry and monitoring mechanisms.\n",
    "\n",
    "If the database needed to be accessed by 100+ people: We may think about putting our solution in a production-scale data warehouse in the cloud, which will have more capacity to service more users and will include workload management to guarantee that resources are distributed equally across users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
